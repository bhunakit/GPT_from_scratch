{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 16\n",
    "x = torch.randn(B, T, C)\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.8077e-01, -6.9988e-02, -3.5962e-01, -9.1520e-01,  6.2577e-01,\n",
      "          2.5510e-02,  9.5451e-01,  6.4349e-02,  3.6115e-01,  1.1679e+00,\n",
      "         -1.3499e+00, -5.1018e-01,  2.3596e-01, -2.3978e-01, -9.2111e-01,\n",
      "          1.5433e+00],\n",
      "        [ 7.6480e-01, -1.0481e-01, -3.6913e-02,  2.4958e-02, -7.0569e-01,\n",
      "          2.5932e-01,  1.2208e+00,  3.2769e-01,  2.4359e-01, -1.9740e-01,\n",
      "         -1.2550e+00, -4.2251e-01,  3.4187e-01, -5.2071e-01,  3.0125e-01,\n",
      "          2.0259e+00],\n",
      "        [ 2.8883e-01, -1.5364e-01,  3.1211e-01,  5.7154e-02, -4.1766e-01,\n",
      "          5.5089e-01,  4.2920e-01,  1.1899e-01, -6.7854e-03, -4.3958e-01,\n",
      "         -6.5443e-01, -7.7993e-01, -1.7399e-01, -1.5653e-01,  1.7141e-03,\n",
      "          1.1194e+00],\n",
      "        [ 6.2801e-01, -3.1597e-01,  5.7193e-01, -2.6114e-02, -6.9095e-01,\n",
      "          9.3936e-01,  1.0126e+00, -3.4739e-01,  3.5781e-01, -7.0725e-01,\n",
      "         -2.8553e-01, -6.3783e-01,  6.4228e-02,  2.6592e-01,  4.0372e-01,\n",
      "          7.3875e-01],\n",
      "        [ 3.3551e-01, -1.3322e-01,  4.4726e-01, -3.3803e-02, -6.5217e-01,\n",
      "          8.4464e-01,  7.5866e-01, -4.9136e-01,  6.8804e-01, -6.7320e-01,\n",
      "         -1.8387e-01, -3.7085e-01, -2.3395e-01,  3.9392e-01,  3.5189e-01,\n",
      "          6.3660e-01],\n",
      "        [ 6.9459e-01, -3.1496e-01,  5.4117e-01,  6.4497e-02, -8.0905e-01,\n",
      "          4.9209e-01,  7.4727e-01, -4.4216e-01,  6.3085e-01, -6.1798e-01,\n",
      "         -7.3911e-02, -4.3677e-01, -2.6479e-01,  2.5544e-01,  1.2638e-01,\n",
      "          4.6226e-01],\n",
      "        [ 3.5723e-01, -4.6499e-01,  4.4021e-01,  1.9275e-01, -6.8897e-01,\n",
      "          3.1581e-01,  5.9798e-01, -3.7654e-01,  5.1541e-01, -5.4876e-01,\n",
      "         -2.1358e-02, -1.7652e-01, -2.0969e-01,  5.8206e-01,  1.6829e-02,\n",
      "          1.1422e-01],\n",
      "        [ 2.7138e-01, -4.0587e-01,  5.0096e-01, -6.6915e-02, -5.8198e-01,\n",
      "          3.3366e-01,  3.0246e-01, -2.5622e-01,  6.6986e-01, -4.4507e-01,\n",
      "          2.0182e-02, -2.3618e-01, -2.6568e-01,  5.4911e-01, -5.3973e-02,\n",
      "         -8.3173e-02]])\n"
     ]
    }
   ],
   "source": [
    "#self-attention v1\n",
    "\n",
    "xbow = torch.zeros((B, T, C))\n",
    "\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1]\n",
    "        xbow[b, t] = torch.mean(xprev, 0)\n",
    "\n",
    "print(xbow[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8077e-01, -6.9988e-02, -3.5962e-01, -9.1520e-01,  6.2577e-01,\n",
       "          2.5510e-02,  9.5451e-01,  6.4349e-02,  3.6115e-01,  1.1679e+00,\n",
       "         -1.3499e+00, -5.1018e-01,  2.3596e-01, -2.3978e-01, -9.2111e-01,\n",
       "          1.5433e+00],\n",
       "        [ 7.6480e-01, -1.0481e-01, -3.6913e-02,  2.4958e-02, -7.0569e-01,\n",
       "          2.5932e-01,  1.2208e+00,  3.2769e-01,  2.4359e-01, -1.9740e-01,\n",
       "         -1.2550e+00, -4.2251e-01,  3.4187e-01, -5.2071e-01,  3.0125e-01,\n",
       "          2.0259e+00],\n",
       "        [ 2.8883e-01, -1.5364e-01,  3.1211e-01,  5.7154e-02, -4.1766e-01,\n",
       "          5.5089e-01,  4.2920e-01,  1.1899e-01, -6.7854e-03, -4.3958e-01,\n",
       "         -6.5443e-01, -7.7993e-01, -1.7399e-01, -1.5653e-01,  1.7140e-03,\n",
       "          1.1194e+00],\n",
       "        [ 6.2801e-01, -3.1597e-01,  5.7193e-01, -2.6114e-02, -6.9095e-01,\n",
       "          9.3936e-01,  1.0126e+00, -3.4739e-01,  3.5781e-01, -7.0725e-01,\n",
       "         -2.8553e-01, -6.3783e-01,  6.4228e-02,  2.6592e-01,  4.0372e-01,\n",
       "          7.3875e-01],\n",
       "        [ 3.3551e-01, -1.3322e-01,  4.4726e-01, -3.3803e-02, -6.5217e-01,\n",
       "          8.4464e-01,  7.5866e-01, -4.9136e-01,  6.8804e-01, -6.7320e-01,\n",
       "         -1.8387e-01, -3.7085e-01, -2.3395e-01,  3.9392e-01,  3.5189e-01,\n",
       "          6.3660e-01],\n",
       "        [ 6.9459e-01, -3.1496e-01,  5.4117e-01,  6.4497e-02, -8.0905e-01,\n",
       "          4.9209e-01,  7.4727e-01, -4.4216e-01,  6.3085e-01, -6.1798e-01,\n",
       "         -7.3911e-02, -4.3677e-01, -2.6479e-01,  2.5544e-01,  1.2638e-01,\n",
       "          4.6226e-01],\n",
       "        [ 3.5723e-01, -4.6499e-01,  4.4021e-01,  1.9275e-01, -6.8897e-01,\n",
       "          3.1581e-01,  5.9798e-01, -3.7654e-01,  5.1541e-01, -5.4876e-01,\n",
       "         -2.1358e-02, -1.7652e-01, -2.0969e-01,  5.8206e-01,  1.6829e-02,\n",
       "          1.1422e-01],\n",
       "        [ 2.7138e-01, -4.0587e-01,  5.0096e-01, -6.6915e-02, -5.8198e-01,\n",
       "          3.3366e-01,  3.0246e-01, -2.5622e-01,  6.6986e-01, -4.4507e-01,\n",
       "          2.0182e-02, -2.3618e-01, -2.6568e-01,  5.4911e-01, -5.3973e-02,\n",
       "         -8.3173e-02]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#self-attention v2\n",
    "\n",
    "w = torch.tril(torch.ones((T, T)))\n",
    "w = w / torch.sum(w, 1, keepdims=True) \n",
    "\n",
    "xbow = w @ x\n",
    "\n",
    "xbow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#self-attention v3\n",
    "\n",
    "tril = torch.tril(torch.ones((T, T)))\n",
    "w = torch.zeros((T, T))\n",
    "w = w.masked_fill(tril==0, float('-inf'))\n",
    "w = F.softmax(w, dim=1)\n",
    "\n",
    "xbow = w @ x\n",
    "\n",
    "xbow[0] \n",
    "\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0152,  0.0849,  0.0156, -0.0755, -0.0138,  0.0720,  0.0097, -0.0505,\n",
       "         -0.0856,  0.0184,  0.0170, -0.0573, -0.0464, -0.0469,  0.0276,  0.0551],\n",
       "        [ 0.0623, -0.0137, -0.0178, -0.0057, -0.0202,  0.0059, -0.0396, -0.0369,\n",
       "         -0.0484,  0.0845,  0.0824, -0.0411,  0.0103,  0.0118,  0.0066,  0.1595],\n",
       "        [ 0.1741, -0.0228, -0.1270,  0.0348,  0.0333, -0.0332, -0.0148, -0.0234,\n",
       "         -0.1168, -0.0624,  0.1308,  0.0149, -0.0893, -0.0227, -0.0331,  0.4593],\n",
       "        [ 0.2850, -0.1001, -0.2212,  0.0618,  0.1816, -0.1536, -0.0042, -0.0282,\n",
       "         -0.0725,  0.0207,  0.0213,  0.0584, -0.0184,  0.0740,  0.1509,  0.5019],\n",
       "        [ 0.3354,  0.1264,  0.0189,  0.1820,  0.2485,  0.0998,  0.1852,  0.1277,\n",
       "         -0.2214, -0.3642, -0.0985, -0.0211, -0.3042,  0.1374,  0.0634,  0.6118],\n",
       "        [ 0.2923,  0.1706, -0.0102,  0.4219,  0.3595,  0.1902,  0.1295,  0.0516,\n",
       "         -0.2165, -0.3195, -0.0527,  0.1205, -0.3123,  0.2185,  0.2450,  0.8324],\n",
       "        [-0.2267,  0.1087, -0.3670,  0.5285,  0.4046, -0.2156, -0.1752, -0.1964,\n",
       "         -0.0706,  0.2379,  0.1594,  0.3987,  0.2636,  0.0427,  0.4868,  0.9587],\n",
       "        [ 0.0178,  0.3965, -1.5167,  0.7820,  0.5193, -0.1152, -0.2868,  1.3367,\n",
       "          0.1130, -0.0694,  0.2526,  1.0655,  0.7209, -1.0938, -0.5096,  0.5521]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#self-attention v4 (ATTENTION IS ALL YOU NEED)\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 32 # example token_embedding + position_embedding\n",
    "x = torch.randn(B, T, C) # represent token embedding\n",
    "\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x) # (B, T, 16)\n",
    "q = query(x) # (B, T, 16)\n",
    "\n",
    "w = q @ k.transpose(-2, -1) * head_size**-0.5 # (B, T, 16) @ (B, 16, T) --> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones((T, T)))\n",
    "# w = torch.zeros((T, T))\n",
    "w = w.masked_fill(tril==0, float('-inf'))\n",
    "w = F.softmax(w, dim=1)\n",
    "\n",
    "v = value(x) # linear transform token embedding \n",
    "\n",
    "xbow = w @ v\n",
    "\n",
    "xbow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1571,  0.8801,  0.1615, -0.7824, -0.1429],\n",
       "        [ 0.8321, -0.8144, -0.3242,  0.5191, -0.1252],\n",
       "        [ 0.6035, -0.2500, -0.6159,  0.4068,  0.3328],\n",
       "        [ 0.6657, -0.7096, -0.6099,  0.4348,  0.8975],\n",
       "        [ 0.1536,  1.0439,  0.8457,  0.2388,  0.3005],\n",
       "        [-0.8920,  0.0578, -0.3350,  0.8477,  0.3876],\n",
       "        [-0.4849,  0.1655, -0.2221, -0.1345, -0.0864],\n",
       "        [ 0.2042,  0.3772, -1.1255,  0.3995,  0.1489]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[0, :, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0964, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0651, 0.0872, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1160, 0.0963, 0.1859, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1823, 0.1080, 0.1677, 0.1842, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1094, 0.1326, 0.1498, 0.1637, 0.2794, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1386, 0.2413, 0.1775, 0.1777, 0.3875, 0.1924, 0.0000, 0.0000],\n",
       "         [0.1967, 0.2156, 0.1709, 0.2105, 0.1955, 0.4954, 0.4261, 0.0000],\n",
       "         [0.0954, 0.1190, 0.1482, 0.2639, 0.1375, 0.3122, 0.5739, 1.0000]],\n",
       "\n",
       "        [[0.1146, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0636, 0.1111, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1215, 0.0961, 0.2046, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1946, 0.1556, 0.2426, 0.1524, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0764, 0.1438, 0.1435, 0.2914, 0.2430, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1094, 0.1381, 0.1263, 0.2249, 0.2046, 0.1662, 0.0000, 0.0000],\n",
       "         [0.1170, 0.2125, 0.1048, 0.2051, 0.2630, 0.4652, 0.5624, 0.0000],\n",
       "         [0.2028, 0.1427, 0.1783, 0.1263, 0.2894, 0.3686, 0.4376, 1.0000]],\n",
       "\n",
       "        [[0.1198, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1352, 0.1368, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0875, 0.1112, 0.1552, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0668, 0.2107, 0.1553, 0.1995, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2464, 0.1157, 0.1797, 0.1653, 0.1593, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1302, 0.1482, 0.1822, 0.1685, 0.2702, 0.3136, 0.0000, 0.0000],\n",
       "         [0.0851, 0.1470, 0.1921, 0.2918, 0.3388, 0.4418, 0.7070, 0.0000],\n",
       "         [0.1290, 0.1304, 0.1355, 0.1749, 0.2318, 0.2446, 0.2930, 1.0000]],\n",
       "\n",
       "        [[0.1499, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1212, 0.0958, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1193, 0.1410, 0.0843, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1119, 0.0942, 0.1623, 0.1115, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1211, 0.1386, 0.1616, 0.1988, 0.1982, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1645, 0.2594, 0.1260, 0.2627, 0.2868, 0.2778, 0.0000, 0.0000],\n",
       "         [0.0940, 0.0853, 0.2217, 0.1424, 0.2015, 0.3990, 0.4141, 0.0000],\n",
       "         [0.1181, 0.1856, 0.2441, 0.2846, 0.3135, 0.3232, 0.5859, 1.0000]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
